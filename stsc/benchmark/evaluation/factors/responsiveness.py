from __future__ import annotations
from typing import List, Dict, Optional
import os
import pickle as pkl

import numpy as np
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
from matplotlib.patches import Circle

import stsc.datagen.predefined_datasets as predata
from stsc.datagen.sequence_sample_set import SequenceSampleSet
from stsc.benchmark.misc.print_writer import PrintWriter
from stsc.benchmark.evaluation.factors.evaluation_factor import EvaluationFactor, ResultsInfoPlotOptions, TestDataset
import stsc.benchmark.evaluation.standard_evaluation_constants as consts
from stsc.benchmark.evaluation.metrics import Metrics
from stsc.benchmark.misc.overrides import overrides
from stsc.benchmark.misc.helpers import path



# TODO (notes):
# - BIC ist recht sensisitv, auch wenn es nur recht wenig samples in einem 2. mode sind, wird 2 "vorgeschlagen" -> anmerken auf webseite, vllt mit einem bild von hier
# - gewichtung und mean distanzen müssen immer zusammengenommen betrachtet werden. bei gewichtung ist eigentlich egal welche komponente welche ist (wenn eine initial etwas stärker ist, ist das für den test hier eigentlich unerheblich)
#
# TODO: diese ganzen prints sollten lauter ja/nein fragen beantworten um gegebenheiten zu prüfen
# TODO (cont.): gebe dann evtl. in klammern noch an wie man da hingekommen ist
# TODO: sammle auch ein paar der werte als "metriken" auf mit 0 oder 1 als ergebniswert
# TODO: organisiere print out: erst kommt geschätzte antwort auf mode collapse frage, dann die einzelfragen und dann block mit erklärungen/berechneten werten
#print()

class Responsiveness(EvaluationFactor):
    """
    Aims to measure the responsiveness of a prediction model, i.e. how many time steps with additional observations it takes the model to collapse an initial bi-modal predictive distribution into a unimodal one, as observed trajectories pass through a T-junction.

    Dataset: T-Maze
    - Resembles a T-junction.
    - Given observations in the test datasets either end prior to the junction or proceed into the junction, thus enforcing a bi-modal or unimodal ground truth distribution for future time steps, respectively.

    Performance Measure: Mode Collapse Indicator
    - Estimates the presence of a mode collapse through several additive sub-indicators. Most sub-indicators are based on a 2-component Gaussian mixture estimated from the sample-based predictive distribution generated by the model.
    -- BIC: Calculates the Bayesian Information Criterion on a single Gaussian distribution and a 2-component Gaussian mixture estimated from the sample-based predictive distribution generated by the model
    -- Intra-Mixture-Distance: Compares the distance of both component mean vectors to a threshold calculated from the ground truth.
    -- Inter-Mixture-Distance: Compares the distance of the predicted mixture to the ground truth mixture.
    -- Prediction-GroundTruth-Distance: Only single component case (BIC == 1). Distance between mean vectors.
    -- Prediction Mixture Weights: Is it heavily biased towards one component?
    """
    def __init__(self, rng: Optional[np.random.Generator] = None) -> None:
        EvaluationFactor.__init__(self, "Test factor: Responsiveness", rng)
        self._init_datasets()
        self._init_gt()

    def _init_datasets(self) -> None:
        data_file_path = path(os.path.join(self._stsc_dir, "files/datasets/responsiveness.pkl"), True)
        if not os.path.exists(data_file_path):
            # We are only using a single training dataset for this evaluation factor
            dg = predata.balanced_tmaze_longtail()
            self._data_gens[dg.name] = dg
            self._training_datasets[dg.name] = dg.sample(200, rng=self._rng)
            # provide 1 test set (left; number of test conditions increases, as we are using multiple observation lengths)
            self._test_datasets[dg.name] = [TestDataset(name="Left", data=dg.sample_component(0, 25, rng=self._rng))] 
            self._dump_datasets(data_file_path)
        else:
            self._load_datasets(data_file_path)

    def _init_gt(self) -> None: 
        # calculate gt distribution sample sets for each observation length
        data_file_path_base = path(os.path.join(self._stsc_dir, "files/datasets/responsiveness_gt"), True)
        if not os.path.exists(f"{data_file_path_base}_samples.pkl"):
            tdname = list(self._data_gens.keys())[0]  # training dataset name
            self._test_sample_seqs = {}
            self._test_posteriors = [{} for _ in range(len(self._test_datasets[tdname][0].data))]
            pred_len = self.prediction_lengths()[0]
            data_gen = self._data_gens[tdname]
            for obs_len in self.observation_lengths():
                s = np.empty(shape=[len(self._test_datasets[tdname][0].data), pred_len, consts.n_gt_samples, 2])
                for i, test_seq in enumerate(self._test_datasets[tdname][0].data):
                    data_gen.posterior(test_seq[:obs_len], list(range(obs_len))) 
                    gmm_seq = data_gen.sequence_distribution()
                    self._test_posteriors[i][obs_len] = data_gen.sequence_distribution()
                    for step in range(pred_len):
                        s[i, step] = gmm_seq(step).sample(n_samples=consts.n_gt_samples, rng=self._rng)
                self._test_sample_seqs[obs_len] = SequenceSampleSet(s)

            with open(f"{data_file_path_base}_samples.pkl", "wb") as f:
                pkl.dump({ol: sss.samples for ol, sss in self._test_sample_seqs.items()}, f)
            with open(f"{data_file_path_base}_posteriors.pkl", "wb") as f:
                pkl.dump(self._test_posteriors, f)
            data_gen.prior()
        else:
            with open(f"{data_file_path_base}_samples.pkl", "rb") as f:
                data = pkl.load(f)
                self._test_sample_seqs = {ol: SequenceSampleSet(samples) for ol, samples in data.items()}
            with open(f"{data_file_path_base}_posteriors.pkl", "rb") as f:
                self._test_posteriors = pkl.load(f)

    @overrides(EvaluationFactor) 
    def observation_lengths(self, *_unused_args, **_unused_kwargs) -> List[int]:
        del _unused_args, _unused_kwargs
        return [4,5,6,7,8,9]

    @overrides(EvaluationFactor)
    def prediction_lengths(self, *_unused_args, **_unused_kwargs) -> List[int]:
        del _unused_args, _unused_kwargs
        return [7]

    @overrides(EvaluationFactor)
    def evaluate_metrics(
        self, 
        prediction_samples: Dict[int,SequenceSampleSet], 
        print_writer: Optional[PrintWriter] = None, 
        results_info_plots_options: Optional[ResultsInfoPlotOptions] = None, 
        model_name: Optional[str] = None
    ) -> Dict[int, Dict[Metrics,float]]: 
        i = self._cur_test_iter_index
        tkey = self._cur_train_iter_key
        pw: PrintWriter = self._setup_print_writer(print_writer)
        self._setup_plot_dir(results_info_plots_options)
        plot_model_prefix = model_name + "_" if model_name is not None else ""
        res_dict = {}

        pw.write_line(f":: Responsiveness [Dataset: {tkey}] ::")
        if model_name is not None:
            pw.write_line(f"Evaluating model: {model_name}")

        collapse_vals_gt = []
        for obs_len in self.observation_lengths(): 
            inp_sample = self._test_datasets[tkey][0].data[i]  

            last_pred = prediction_samples[obs_len].step_samples(i, -1)
            last_gt = self._test_sample_seqs[obs_len].step_samples(i, -1)

            gm_pred_k1 = GaussianMixture(n_components=1, random_state=0).fit(last_pred)
            gm_pred_k2 = GaussianMixture(n_components=2, random_state=0).fit(last_pred)
            gm_gt_k1 = GaussianMixture(n_components=1, random_state=0).fit(last_gt)
            gm_gt_k2 = GaussianMixture(n_components=2, random_state=0).fit(last_gt)

            max_var = np.max([np.max(np.diag(mat)) for mat in self._test_posteriors[i][obs_len].covar_matrices[0][7]])
            dist_thresh = 3*np.sqrt(max_var)
            gt_bic_n_comps = 1 if gm_gt_k1.bic(last_gt) < gm_gt_k2.bic(last_gt) else 2
            pred_bic_n_comps = 1 if gm_pred_k1.bic(last_gt) < gm_pred_k2.bic(last_gt) else 2
            gt_gm_comp_means_dist = np.linalg.norm(gm_gt_k2.means_[0] - gm_gt_k2.means_[1])
            pred_gm_comp_means_dist = np.linalg.norm(gm_pred_k2.means_[0] - gm_pred_k2.means_[1])
            gt_gm_k1_k2_dists = [np.linalg.norm(gm_gt_k2.means_[0] - gm_gt_k1.means_[0]), np.linalg.norm(gm_gt_k2.means_[1] - gm_gt_k1.means_[0])]
            pred_gm_k1_k2_dists = [np.linalg.norm(gm_pred_k2.means_[0] - gm_pred_k1.means_[0]), np.linalg.norm(gm_pred_k2.means_[1] - gm_pred_k1.means_[0])]
            pred_gt_dist = np.linalg.norm(gm_pred_k1.means_[0] - gm_gt_k1.means_[0])

            # calculate mode collapse indicators
            bic_ind = int(gt_bic_n_comps == 1 and pred_bic_n_comps == 1)
            intra_gm_dist_ind = int(pred_gm_comp_means_dist < dist_thresh)
            inter_gm_dist_ind = int(pred_gm_k1_k2_dists[0] < dist_thresh and pred_gm_k1_k2_dists[1] < dist_thresh)
            gm_pred_gt_dist_ind = int(gt_bic_n_comps == 1 and pred_gt_dist < dist_thresh) 
            weighting_ind = int((pred_bic_n_comps == 2 and np.max(gm_pred_k2.weights_) > 0.95) or pred_bic_n_comps == 1) 
            ind_sum = bic_ind + intra_gm_dist_ind + inter_gm_dist_ind + gm_pred_gt_dist_ind + weighting_ind

            collapse_vals_gt.append(float(gt_bic_n_comps == 1))
            res_dict[obs_len] = {
                Metrics.RESP_COLLAPSE: ind_sum / 5.,
                Metrics.RESP_IND_BIC: float(bic_ind),
                Metrics.RESP_IND_INTRA_DIST: float(intra_gm_dist_ind),
                Metrics.RESP_IND_INTER_DIST: float(inter_gm_dist_ind),
                Metrics.RESP_IND_PRED_GT_DIST: float(gm_pred_gt_dist_ind),
                Metrics.RESP_IND_GM_WEIGHTS: float(weighting_ind)
            }

            pw.buffer_line(f"Observation length: {obs_len}")
            pw.buffer_line(f"Mode Collapsed: {ind_sum / 5. * 100}% (expected: {gt_bic_n_comps == 1})")
            pw.buffer_line("Indicators:")
            pw.buffer_line(f"  BIC: {bic_ind}")
            pw.buffer_line(f"  Intra GM distance: {intra_gm_dist_ind}")
            pw.buffer_line(f"  Inter GM distance: {inter_gm_dist_ind}")
            pw.buffer_line(f"  Pred GM - GT GM distance: {gm_pred_gt_dist_ind} [only evaluated if gt bic suggests k=1, else 0 by default]")
            pw.buffer_line(f"  Pred GM weight bias (>0.95): {weighting_ind} [only evaluated if ored bic suggests k=2, else 1 by default]")
            pw.buffer_line("")
            pw.buffer_line("Calculated values:")
            pw.buffer_line(f"  BIC n comps (GT): {gt_bic_n_comps}") 
            pw.buffer_line(f"  BIC n comps (pred): {pred_bic_n_comps}") 
            pw.buffer_line(f"  Intra GM (k=2) mean vecs dist (gt): {gt_gm_comp_means_dist}")
            pw.buffer_line(f"  Intra GM (k=2) mean vecs dist (pred): {pred_gm_comp_means_dist}")
            pw.buffer_line(f"  Inter GM mean vecs dists (k=2 -> k=1) (gt): {gt_gm_k1_k2_dists} (note: [d(m_k2[0], m_k1), d(m_k2[1], m_k1)] )")
            pw.buffer_line(f"  Inter GM dists (k=2 -> k=1) (pred): {pred_gm_k1_k2_dists} (note: [d(m_k2[0], m_k1), d(m_k2[1], m_k1)] )")
            pw.buffer_line(f"  Pred -> GT GM mean vec dist (k=1): {pred_gt_dist}")
            pw.buffer_line(f"  GM Weights (k=2, gt) {gm_gt_k2.weights_}")
            pw.buffer_line(f"  GM Weights (k=2, pred) {gm_pred_k2.weights_}")
            pw.buffer_line("")
            pw.buffer_line("")
            pw.flush()

            if results_info_plots_options is not None:
                plt.figure()
                plt.plot(last_gt[:, 0], last_gt[:, 1], "bs", markerfacecolor="none", alpha=0.5, label="gt")
                plt.plot(last_pred[:, 0], last_pred[:, 1], "rs", markerfacecolor="none", alpha=0.5, label="pred")
                plt.plot(inp_sample[:, 0], inp_sample[:, 1], "ko--")
                plt.plot(inp_sample[:obs_len, 0], inp_sample[:obs_len, 1], "go")
                if results_info_plots_options.show_titles:
                    plt.title(f"evaluated samples (obs len: {obs_len})")
                plt.legend()
                plt.savefig(f"{results_info_plots_options.directory_path}/{plot_model_prefix}responsiveness_evaluated_samples_obs-{obs_len}.png", dpi=300, bbox_inches="tight")
                plt.close()

                plt.figure()
                plt.plot(inp_sample[:, 0], inp_sample[:, 1], "ko--")
                plt.plot(inp_sample[:obs_len, 0], inp_sample[:obs_len, 1], "go")
                plt.plot(gm_gt_k2.means_[:, 0], gm_gt_k2.means_[:, 1], "b*", markersize=10, markerfacecolor="none", label="gt (k=2)")
                plt.plot(gm_gt_k1.means_[:, 0], gm_gt_k1.means_[:, 1], "bd", markersize=10, markerfacecolor="none", label="gt (k=1)")
                plt.plot(gm_pred_k2.means_[:, 0], gm_pred_k2.means_[:, 1], "r*", markersize=10, markerfacecolor="none", label="pred (k=2)")
                plt.plot(gm_pred_k1.means_[:, 0], gm_pred_k1.means_[:, 1], "rd", markersize=10, markerfacecolor="none", label="pred (k=1)")
                plt.gca().add_patch(Circle(gm_gt_k2.means_[0], radius=dist_thresh, edgecolor="b", facecolor="none"))
                plt.gca().add_patch(Circle(gm_gt_k2.means_[1], radius=dist_thresh, edgecolor="b", facecolor="none"))
                plt.gca().add_patch(Circle(gm_gt_k1.means_[0], radius=dist_thresh, edgecolor="b", linestyle="--", facecolor="none"))
                if results_info_plots_options.show_titles:
                    plt.title(f"GM means and dist thresh circles (obs len: {obs_len})")
                plt.legend()
                plt.savefig(f"{results_info_plots_options.directory_path}/{plot_model_prefix}responsiveness_gm_means_obs-{obs_len}.png", dpi=300, bbox_inches="tight")
                plt.close()

        if results_info_plots_options is not None:
            x_vals = self.observation_lengths()
            y_vals = [res_dict[ol][Metrics.RESP_COLLAPSE] for ol in x_vals]
            plt.figure()
            plt.plot(x_vals, y_vals, "r-", label="pred")
            plt.plot(x_vals, collapse_vals_gt, "b--", label="gt")
            if results_info_plots_options.show_titles:
                plt.title("collapse percentage")
            plt.legend()
            plt.savefig(f"{results_info_plots_options.directory_path}/{plot_model_prefix}responsiveness_collapse_perc.png", dpi=300, bbox_inches="tight")
            plt.close()
        
        return res_dict


